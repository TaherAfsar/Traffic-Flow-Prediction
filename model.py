# -*- coding: utf-8 -*-
"""60009230212_ML1_Mini_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cdmz53FZ9nm1pgDPLA93lfwZrpkpyABx

**Name: Taher Afsar**

**SAP: 60009230212**

**Roll no: D137**

**Batch: D2-2**

**Title**: Traffic Flow Prediction**

**Aim**: The aim of this project is to develop a predictive model that recommends the most suitable junction for travel between two points based on historical traffic data and user-specified parameters such as time of day.

*Importing Libraries*
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""# Data Description

*Reading the datset*
"""

df = pd.read_csv('./dataset/traffic.csv')

df

"""Understanding the data types"""

df.info()

df.describe()

"""*Checking for null values*"""

df.isna().sum()

"""*Checking for duplicates*"""

df.duplicated().sum()

"""*Visualizing the distribution of 'Vehicles' column*"""

plt.figure(figsize=(8, 6))
sns.histplot(df['Vehicles'], bins=20, kde=True)
plt.title('Distribution of Vehicles')
plt.xlabel('Number of Vehicles')
plt.ylabel('Frequency')
plt.show()

"""# Data Preprocessing

*Group data by hour and calculate the average number of vehicles*
"""

df['DateTime'] = pd.to_datetime(df['DateTime'])

# Extract year, month, day, hour, and minute features
df['Year'] = df['DateTime'].dt.year
df['Month'] = df['DateTime'].dt.month
df['Day'] = df['DateTime'].dt.day
df['Hour'] = df['DateTime'].dt.hour
df['Minute'] = df['DateTime'].dt.minute

# Drop the original 'DateTime' column
df.drop(columns=['DateTime'], inplace=True)
hourly_avg_vehicles = df.groupby('Hour')['Vehicles'].mean().reset_index()

# Plot the distribution of estimated vehicles based on time of day
plt.figure(figsize=(10, 6))
sns.barplot(x='Hour', y='Vehicles', data=hourly_avg_vehicles, color='skyblue')
plt.title('Estimated Vehicles Distribution by Time of Day')
plt.xlabel('Hour of the Day')
plt.ylabel('Average Number of Vehicles')
plt.xticks(rotation=45)
plt.show()

"""*Heatmap*"""

correlation_matrix = df.corr()

# Plotting the correlation matrix
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix')
plt.show()

"""*Scatter Plot*"""

plt.figure(figsize=(10, 6))
sns.scatterplot(data=df, x='Vehicles', y='Junction')
plt.title('Scatter Plot of Vehicles vs Junction')
plt.xlabel('Vehicles')
plt.ylabel('Junction')
plt.show()

"""*Box Plot*"""

plt.figure(figsize=(10, 6))
sns.boxplot(data=df, x='Junction', y='Vehicles')
plt.title('Box Plot of Vehicles by Junction')
plt.xlabel('Junction')
plt.ylabel('Vehicles')
plt.show()

"""*Seasonal Decomposition*"""

from statsmodels.tsa.seasonal import seasonal_decompose

result = seasonal_decompose(df['Vehicles'], model='additive', period=24)  # Assuming daily seasonality
result.plot()
plt.show()

"""*Outlier Detection and Removal*"""

plt.figure(figsize=(10, 6))
sns.histplot(df['Vehicles'], bins=30, kde=True, color='skyblue')
plt.title('Distribution of Vehicles (Before Outlier Removal)')
plt.xlabel('Number of Vehicles')
plt.ylabel('Frequency')
plt.show()



Q1 = df['Vehicles'].quantile(0.25)
Q3 = df['Vehicles'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
outliers = df[(df['Vehicles'] < lower_bound) | (df['Vehicles'] > upper_bound)]
cleaned_df = df[~df['Vehicles'].isin(outliers['Vehicles'])]



plt.figure(figsize=(10, 6))
sns.histplot(cleaned_df['Vehicles'], bins=30, kde=True, color='skyblue')
plt.title('Distribution of Vehicles (After Outlier Removal)')
plt.xlabel('Number of Vehicles')
plt.ylabel('Frequency')
plt.show()

"""*Feature Engineering*"""

def time_of_day(hour):
    if 6 <= hour < 12:
        return 'Morning'
    elif 12 <= hour < 18:
        return 'Afternoon'
    elif 18 <= hour < 24:
        return 'Evening'
    else:
        return 'Night'

df['TimeOfDay'] = df['Hour'].apply(time_of_day)
df.head()



df

df.columns

df['Junction'].value_counts()

df['Hour']

df['TimeOfDay'].value_counts()

df.drop(columns=['ID', 'Minute', 'Year'], inplace=True)

df.head()

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

df['TimeOfDay'] = le.fit_transform(df['TimeOfDay'])

df.head()

from sklearn.ensemble import RandomForestRegressor
import matplotlib.pyplot as plt

# Include Date feature in the model training data
X = df.drop(columns=['Vehicles'])
y = df['Vehicles']

# Assuming 'Date' is a column in the DataFrame
# If not, you need to extract the date from the 'DateTime' column
X['Date'] = df['Date']

# Train your model using the updated X with Date feature

rf = RandomForestRegressor(n_estimators=100, random_state=42)

rf.fit(X, y)

importances = rf.feature_importances_

indices = np.argsort(importances)[::-1]

names = [X.columns[i] for i in indices]

plt.figure(figsize=(10, 6))
plt.title("Feature Importance")
plt.bar(range(X.shape[1]), importances[indices])
plt.xticks(range(X.shape[1]), names, rotation=90)
plt.show()

df = df.drop('TimeOfDay',axis=1)

df

"""# Model Selection"""

from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error

X = df.drop(columns=['Vehicles'])
y = df['Vehicles']

models = {
    "Linear Regression": LinearRegression(),
    "Decision Tree": DecisionTreeRegressor(random_state=42),
    "Random Forest": RandomForestRegressor(n_estimators=100, random_state=42),
    "Gradient Boosting": GradientBoostingRegressor(n_estimators=100, random_state=42)
}

results = {}
for name, model in models.items():
    scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_absolute_error')
    results[name] = np.mean(scores)

for name, score in results.items():
    print(f"{name}: {abs(score)}")

model_names = list(results.keys())
mae_scores = [abs(score) for score in results.values()]

plt.figure(figsize=(14, 8))
bars = plt.bar(model_names, mae_scores, color='skyblue')

for bar, score in zip(bars, mae_scores):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.5, f'{score:.2f}', ha='center', va='bottom')

plt.xlabel('Model')
plt.ylabel('Mean Absolute Error')
plt.title('Mean Absolute Error for Different Models')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

results_r2 = {}

for name, model in models.items():
    scores_r2 = cross_val_score(model, X, y, cv=5, scoring='r2')
    results_r2[name] = np.mean(np.abs(scores_r2))
print("R-squared Score:")
for name, score in results_r2.items():
    print(f"{name}: {score}")

model_names = list(results_r2.keys())
r2_scores = list(results_r2.values())

plt.figure(figsize=(10, 6))
bars = plt.bar(model_names, r2_scores, color='lightgreen')

for bar, score in zip(bars, r2_scores):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.005, f'{score:.2f}', ha='center', va='bottom')

plt.xlabel('Model')
plt.ylabel('R-squared Score')
plt.title('R-squared Score for Different Models')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

from sklearn.model_selection import cross_val_predict

results_mape = {}
for name, model in models.items():
    y_pred = cross_val_predict(model, X, y, cv=5)
    mape = np.mean(np.abs((y - y_pred) / y)) * 100
    results_mape[name] = mape

print("Mean Absolute Percentage Error (MAPE):")
for name, score in results_mape.items():
    print(f"{name}: {score:.2f}%")

model_names = list(results_mape.keys())
mape_scores = list(results_mape.values())

plt.figure(figsize=(10, 6))
bars = plt.bar(model_names, mape_scores, color='orange')

for bar, score in zip(bars, mape_scores):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.5, f'{score:.2f}%', ha='center', va='bottom')

plt.xlabel('Model')
plt.ylabel('Mean Absolute Percentage Error (MAPE)')
plt.title('Mean Absolute Percentage Error (MAPE) for Different Models')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""We conducted a comprehensive analysis to determine the best regression model for predicting the number of vehicles in your dataset. Here are the key findings:

1. **Mean Absolute Error (MAE)**:
   - Linear Regression: 13.93
   - Decision Tree: 15.36
   - Random Forest: 15.16
   - Gradient Boosting: 13.43
   
   The lower the MAE, the better the model's prediction accuracy. In this regard, Linear Regression and Gradient Boosting outperform Decision Tree and Random Forest.

2. **Mean Absolute Percentage Error (MAPE)**:
   - Linear Regression: 105.73%
   - Decision Tree: 86.50%
   - Random Forest: 84.98%
   - Gradient Boosting: 74.67%
   
   MAPE provides insight into the percentage error in predictions. Once again, Gradient Boosting exhibits the lowest MAPE, indicating superior prediction accuracy compared to other models.

3. **R-squared Score**:
   - Linear Regression: 0.91
   - Decision Tree: 1.27
   - Random Forest: 1.13
   - Gradient Boosting: 0.62
   
   R-squared measures the proportion of variance in the dependent variable that is predictable from the independent variables. Higher values indicate a better fit of the model to the data. Here, Decision Tree and Random Forest show higher R-squared scores, suggesting they explain more variance in the number of vehicles.

Based on these findings, **Gradient Boosting** emerges as the most suitable model for predicting the number of vehicles in our dataset. Despite having a relatively lower R-squared score compared to Decision Tree and Random Forest, Gradient Boosting offers superior prediction accuracy with lower MAE
and MAPE. This indicates that Gradient Boosting provides more reliable and precise predictions, making it the preferred choice for your regression task.
"""

from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error

X = df.drop(columns=['Vehicles'])
y = df['Vehicles']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

model = GradientBoostingRegressor(n_estimators=100, random_state=42)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
print("Mean Absolute Error (MAE):", mae)

"""# Cross Validation"""

from sklearn.model_selection import cross_val_score

cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_absolute_error')

cv_scores = -cv_scores

print("Cross-Validation Mean Absolute Error (MAE):", cv_scores.mean())
print("Cross-Validation Standard Deviation:", cv_scores.std())

cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_absolute_error')

cv_scores = -cv_scores

plt.figure(figsize=(8, 6))
plt.boxplot(cv_scores, vert=False)
plt.xlabel('Mean Absolute Error (MAE)')
plt.title('Cross-Validation MAE Scores')
plt.show()

"""The cross-validation analysis provides valuable insights into the performance of the Gradient Boosting Regressor model for predicting the number of vehicles. Here's an analysis based on the provided cross-validation metrics:

1. **Mean Absolute Error (MAE)**:
   - The mean cross-validation MAE score is approximately 13.43.
   - This indicates that, on average, the model's predictions deviate from the actual values by around 13.43 vehicles.
   - MAE is an absolute measure of error, making it easy to interpret in the context of the target variable.

2. **Standard Deviation**:
   - The standard deviation of the cross-validation MAE scores is approximately 8.94.
   - Standard deviation measures the dispersion or variability of the cross-validation scores around the mean.
   - A higher standard deviation indicates greater variability in model performance across different folds of the cross-validation.


Overall, the cross-validation analysis indicates that the Gradient Boosting Regressor model shows promise for predicting the number of vehicles.
"""

y_pred_all = model.predict(X)

plt.figure(figsize=(8, 6))
plt.scatter(y, y_pred_all, color='blue', alpha=0.5)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)
plt.xlabel('Actual Number of Vehicles')
plt.ylabel('Predicted Number of Vehicles')
plt.title('Actual vs Predicted Number of Vehicles')
plt.grid(True)
plt.show()

from joblib import dump

dump(model, 'traffic_model.pkl', protocol=4)

df.columns

while True:
    junction = int(input("Enter junction number (1, 2, 3 or 4): "))
    month = int(input("Enter month (1-12): "))
    day = int(input("Enter day (1-31): "))
    hour = int(input("Enter hour (0-23): "))

    input_data = pd.DataFrame({
        'Junction': [junction],
        'Month': [month],
        'Day': [day],
        'Hour': [hour]
    })

    predicted_vehicles = model.predict(input_data)

    predicted_vehicles = round(predicted_vehicles[0])

    print("Predicted number of vehicles:", predicted_vehicles)

    cont = input("Do you want to predict again? (yes/no): ")
    if cont.lower() != 'yes':
        break